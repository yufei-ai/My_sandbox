{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Image Recognition\n",
    "\n",
    "> ### The human visual system is one of the wonders of the world.\n",
    "\n",
    "We carry in our heads a supercomputer. Our brain has billions of neurons, with even more connections between them, all tuned by evolution over hundreds of millions of years to be superbly adapted to understand the visual world.\n",
    "\n",
    "> ### This machine learning system knows its Chihuahuas from its Pomeranians. Using pixels alone.\n",
    "\n",
    "Over the past four years you have doubtlessly noticed quantum leaps in the quality of everyday technologies. Take your photo collection - you can now search or automatically organize collections of photos with no identifying tags. \n",
    "\n",
    "Think about that. To gather up dog pictures, the app must identify anything from a Chihuahua (or Pomeranian) to a German shepherd and not be tripped up if the pup is depicted upside down or partially obscured, at the right or the left of the frame, in fog or snow, sun or shade.\n",
    "\n",
    "Artificial neural networks are the fundamental programmes making it possible for machines to replicate the performance of the human visual system. Here we give you access to a neural network, which has many millions of neurons, for you to put to the task of recognising any image. Your move.\n",
    "\n",
    "_Text inspired by Nielsen ([2015](http://neuralnetworksanddeeplearning.com/chap1.html)) and Parloff ([2016](http://fortune.com/ai-artificial-intelligence-deep-machine-learning/))._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label custom images\n",
    "\n",
    "#### 1. Upload your JPEG photo in the `data` directory\n",
    "- Switch to the workspace tab on SherlockML, navigate to the `Image Recognition > data` directory and use the `Upload` feature at the top-right corner.\n",
    "\n",
    "#### 2. Run the machine learning model by selecting `Cell` and `Run All`\n",
    "\n",
    "\n",
    "#### 3. View results for different images using the drop-down menu\n",
    "\n",
    "_We have provided photos of our beautiful office Chihuahuas (`toby.JPG` & `chibi.JPG`)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've put all the important functions in a helper module. To have a look at the code, open `image_recognition.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import image_recognition as imrec\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classify all images in the given directory\n",
    "descriptions = imrec.classify_jpgs('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should take under a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae0ca1e58f146c3880aaa368d6dc9a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive widget\n",
    "jpgs_tuple = descriptions.keys()\n",
    "# suppress unwanted widget text output with semi-colon\n",
    "widgets.interact(lambda x: imrec.endlos(x, descriptions, 'data'), x=jpgs_tuple);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical details\n",
    "\n",
    "__This demo__ classifies custom JPEG images using the pre-trained [Inception-v3](https://www.tensorflow.org/versions/r0.11/tutorials/image_recognition/index.html) model distributed with the [TensorFlow](https://www.tensorflow.org/) library. \n",
    "\n",
    "Inception-v3 is trained on [ILSVRC2014](http://image-net.org/challenges/LSVRC/2014/index#data), a variant of the ImageNet database consisting of 1.2 million images and 1,000 categories. It follows that this demo is capable of recognising 1,000 different types of objects as diverse as leopards, dishwashers and hats. \n",
    "\n",
    "__The Inception-v3 model__ is a special type of convolutional neural network, and contains about 25 million parameters. Even though this is a large number, Inception-v3 makes use of fewer parameters than competitor models such as AlexNet (60 million) and VGGNet (~135 million), while outperforming both. \n",
    "\n",
    "Inception-v3 correctly labels an image with its top prediction 78% of the time, whereas AlexNet (2012) and VGGNet (2014) achieve 54% and 70% top-prediction accuracy respectively ([Canziani et al.](https://arxiv.org/abs/1605.07678)). The top 5 predictions of Inception-v3 contained the correct label for the image 94% of the time when tested on the [ILSVRC2012](http://image-net.org/challenges/LSVRC/2012/) variant of the ImageNet dataset ([Szegedy et al.](https://arxiv.org/abs/1512.00567)).\n",
    "\n",
    "It is therefore to be expected that this demo will feature the correct label for a given image at most 94% of the time. On an intuitive level, this is because user-provided images will only partly be comparable with those from the ImageNet database. \n",
    "\n",
    "__Training__ of the Inception-v3 model that is distributed alongside TensorFlow was seemingly run on a powerful computer with 128GB of CPU RAM and 8 NVIDIA Tesla K40 GPU cards. Replicating this feat on a normal desktop machine is clearly impossible. But, while training Inception-v3 demands substantial computational resources, classification of images with this model is relatively 'simple'. It takes Inception-v3 around 5 billion multiply-add operations to process a single image. Don't be deceived by the apparent magnitude of this number, modern machines can nowadays complete the task in few seconds. \n",
    "\n",
    "Performance for images that depict humans has been [observed](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/07_Inception_Model.ipynb) to still be a struggle for Inception-v3. Dogs, however... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think you can beat the machine at recognising images? You can [test yourself here](http://cs.stanford.edu/people/karpathy/ilsvrc/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
