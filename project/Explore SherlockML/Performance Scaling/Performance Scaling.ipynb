{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seamless Performance Scaling in SherlockML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical data science workloads run on large data sets can take days to complete. In this demonstration we will show how Sherlock makes it very easy for you to ask for more computational resources, when (and only when!) you need it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a subset of the `Adult` dataset which can be obtained from the UCI website at the following address: https://archive.ics.uci.edu/ml/datasets/Adult. This dataset consists of over 30K records extracted from the 1994 American census. The prediction task at hand is to determine whether an individual's income exceeds 50K $ / year or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['Age', 'Work Class', 'FNLWGT', 'Education', 'Education Number', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours Per Week', 'Native Country', 'Income Class']\n",
    "column_types = {'Age': np.int32 ,'Work Class' : 'category', 'FNLWGT' : np.int32 , 'Education': 'category', 'Education Number': np.int32, 'Marital Status': 'category', 'Occupation':'category', 'Relationship':'category', 'Race':'category', 'Sex':'category', 'Capital Gain' : np.int32, 'Capital Loss' : np.int32, 'Hours Per Week' : np.int32, 'Native Country' : 'category', 'Income Class' : 'category'   }\n",
    "adult = pd.read_csv('data/adult_adapted.data', header = None, names =  columns, dtype = column_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(adult.drop(['Income Class', 'FNLWGT'], axis = 1)).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = adult['Income Class'].cat.codes.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this classification problem we will use a Random Forest classifier, which is part of the `sklearn` library. Random forests are good general-purpose classifiers which work well in a wide variety of prediction tasks. In addition, their performance scales very well with the number of processing cores available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble as es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = es.RandomForestClassifier(n_estimators = 300, n_jobs = -1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   14.4s finished\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X,Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly test our classifier on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_test = pd.read_csv('data/adult_adapted.test', header = None, names =  columns, dtype = column_types)\n",
    "test_country = pd.Categorical(adult_test['Native Country'], categories = list(adult['Native Country'].unique()))\n",
    "adult_test['Native Country'] = test_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(adult_test.drop(['Income Class', 'FNLWGT'], axis = 1)).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_true = adult_test['Income Class'].cat.codes.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done 120 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 300 out of 300 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50k       0.88      0.92      0.90     11360\n",
      "       >50K       0.73      0.61      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_true, Y_pred, target_names=['<=50k', '>50K']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our off-the-shelf classifier achieves decent results, but takes roughly 10 seconds to train. Can we do better? With Sherlock, running your notebook on a faster computer is only a few clicks away. Let's give it a go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a larger server\n",
    "<img src=\"images/create_instance.png\" alt=\"Upload directions\" style=\"width: 500px; float: right; margin-right:10px;\"/>\n",
    "\n",
    "#### 1. Close  this notebook.\n",
    "\n",
    "\n",
    "#### 2. In the workspace view, click on the down arrow next to the `default` label, then click on `Create server`.\n",
    "\n",
    "#### 3. Select `Extra large (8 cores, 32 GB memory)` from the `SIZE` drop-down menu, give your server a name and click on `Create instance`. Wait a few seconds for your new server to be ready, then select it.\n",
    "\n",
    "#### 4. That's it!  When you no longer need your more powerful server, you can easily terminate it by clicking on the Servers tab on the left hand side panel and selecting 'Terminate' from the drop down menu which will appear after clicking on the three dots displayed to the right of the name of your server.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this notebook again. Training the classifier now only takes about 2.5 seconds, which is a 4X speed-up! Real-world data science tasks can take days to complete, and require a lot of computational resources. Without Sherlock, transferring all your data and libraries to a bigger AWS instance would be no mean feat, and would require a lot of time - and hence money. But Sherlock does it all for you under the hood, in a seamless and secure fashion.\n",
    "\n",
    "Using the command line and the `sml` package, it is possible possible to create even larger servers, with more than 100 cores. This is especially useful when working on the most demanding projects."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
